#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å·¥å…·ç±» (Utility Classes)
åŒ…å«Api-Finderä¸­ä½¿ç”¨çš„é€šç”¨åŠŸèƒ½ (Contains common functionality used in Api-Finder)
"""

import re
import yaml
import requests
from datetime import datetime, timedelta
from urllib.parse import urlparse
from .config import DEFAULT_CONFIG

def load_rules():
    """ä» rules.yaml åŠ è½½è§„åˆ™"""
    import os
    rules_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'config', 'rules.yaml')
    with open(rules_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

RULES = load_rules()

class URLProcessor:
    """URLå¤„ç†å·¥å…·ç±» (URL processing utility class)"""
    
    @staticmethod
    def process_url(base_url, relative_url):
        """
        å¤„ç†ç›¸å¯¹URLï¼Œè½¬æ¢ä¸ºç»å¯¹URL (Process relative URL, convert to absolute URL)
        
        Args:
            base_url (str): åŸºç¡€URL (Base URL)
            relative_url (str): ç›¸å¯¹URL (Relative URL)
            
        Returns:
            str: ç»å¯¹URL (Absolute URL)
        """
        black_url = ["javascript:"]
        url_raw = urlparse(base_url)
        ab_url = url_raw.netloc
        host_url = url_raw.scheme
        
        if relative_url[0:2] == "//":
            result = host_url + ":" + relative_url
        elif relative_url[0:4] == "http":
            result = relative_url
        elif relative_url[0:2] != "//" and relative_url not in black_url:
            if relative_url[0:1] == "/":
                result = host_url + "://" + ab_url + relative_url
            else:
                if relative_url[0:1] == ".":
                    if relative_url[0:2] == "..":
                        result = host_url + "://" + ab_url + relative_url[2:]
                    else:
                        result = host_url + "://" + ab_url + relative_url[1:]
                else:
                    result = host_url + "://" + ab_url + "/" + relative_url
        else:
            result = base_url
        return result

class URLExtractor:
    """URLæå–å·¥å…·ç±» (URL extraction utility class)"""
    
    @staticmethod
    def extract_urls(js_content):
        """
        ä»JavaScriptå†…å®¹ä¸­æå–URL (Extract URLs from JavaScript content)
        
        Args:
            js_content (str): JavaScriptå†…å®¹ (JavaScript content)
            
        Returns:
            list: æå–åˆ°çš„URLåˆ—è¡¨ (List of extracted URLs)
        """
        filter_key = DEFAULT_CONFIG["filter_extensions"]
        pattern_raw = RULES.get('url_extractor_pattern', '')
        ignored_domains = RULES.get('ignored_domains', [])

        pattern = re.compile(pattern_raw, re.VERBOSE)
        result = re.finditer(pattern, str(js_content))
        urls = []
        
        if result is None:
            return urls
            
        for match in result:
            url = match.group().strip('"').strip("'")
            if any(sub in url for sub in filter_key):
                continue
            if any(domain in url for domain in ignored_domains):
                continue
            
            urls.append(url)
        
        return urls

class UpdateManager:
    """æ›´æ–°ç®¡ç†å·¥å…·ç±»"""

    @staticmethod
    def get_current_timestamp():
        """è·å–å½“å‰æ—¶é—´çš„ YYYYMMDDHHMMSS æ ¼å¼æ—¶é—´æˆ³"""
        return datetime.now().strftime('%Y%m%d%H%M%S')

    @staticmethod
    def check_for_updates(force_update=False):
        """
        æ£€æŸ¥å¹¶æ‰§è¡Œè§„åˆ™æ–‡ä»¶æ›´æ–°, ä¼šåˆå¹¶ç”¨æˆ·è‡ªå®šä¹‰çš„åˆ—è¡¨è§„åˆ™ã€‚
        
        Args:
            force_update (bool): æ˜¯å¦å¼ºåˆ¶æ›´æ–°
        """
        local_rules = RULES
        last_check_str = str(local_rules.get('last_check_timestamp', '20000101000000'))
        last_check_time = datetime.strptime(last_check_str, '%Y%m%d%H%M%S')
        update_interval = timedelta(days=DEFAULT_CONFIG['update_interval_days'])

        if not force_update and (datetime.now() - last_check_time < update_interval):
            return

        from rich.console import Console
        from rich.panel import Panel
        console = Console()
        
        try:
            remote_url = DEFAULT_CONFIG['remote_rules_url']
            response = requests.get(remote_url, timeout=DEFAULT_CONFIG['timeout'])
            response.raise_for_status()
            
            remote_rules = yaml.safe_load(response.text)
            local_version = str(local_rules.get('version_timestamp', '0'))
            remote_version = str(remote_rules.get('version_timestamp', '0'))
            
            rules_updated = False
            if force_update or remote_version > local_version:
                if force_update:
                    console.print(Panel("ğŸ”„ [bold yellow]å¼ºåˆ¶æ›´æ–°è§„åˆ™...[/bold yellow]", border_style="yellow"))
                else:
                    console.print(Panel(f"ğŸ†• [bold green]å‘ç°æ–°ç‰ˆæœ¬è§„åˆ™ (v{remote_version})ï¼Œæ­£åœ¨åˆå¹¶è§„åˆ™...[/bold green]", border_style="green"))

                # --- åˆå¹¶é€»è¾‘ ---
                # ä»¥è¿œç¨‹è§„åˆ™ä¸ºåŸºç¡€è¿›è¡Œåˆå¹¶
                merged_rules = remote_rules.copy()

                # åˆå¹¶æ‰€æœ‰åˆ—è¡¨ç±»å‹çš„å€¼
                for key, local_value in local_rules.items():
                    if isinstance(local_value, list):
                        remote_value = merged_rules.get(key, [])
                        if isinstance(remote_value, list):
                            # åˆå¹¶æœ¬åœ°å’Œè¿œç¨‹åˆ—è¡¨å¹¶å»é‡
                            merged_list = sorted(list(set(local_value + remote_value)))
                            merged_rules[key] = merged_list
                
                # æ›´æ–°æœ€åæ£€æŸ¥æ—¶é—´æˆ³
                merged_rules['last_check_timestamp'] = UpdateManager.get_current_timestamp()

                import os
                rules_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'config', 'rules.yaml')
                with open(rules_path, 'w', encoding='utf-8') as f:
                    yaml.dump(merged_rules, f, allow_unicode=True, sort_keys=False)
                
                console.print("âœ… [bold green]è§„åˆ™æ–‡ä»¶æ›´æ–°å¹¶åˆå¹¶æˆåŠŸã€‚[/bold green]")
                rules_updated = True

            else:
                console.print("â„¹ï¸ [bold cyan]æœ¬åœ°è§„åˆ™å·²æ˜¯æœ€æ–°ç‰ˆæœ¬ã€‚[/bold cyan]")

            # å¦‚æœè§„åˆ™æ²¡æœ‰æ›´æ–°ï¼Œä»…æ›´æ–°æ£€æŸ¥æ—¶é—´æˆ³
            if not rules_updated:
                local_rules['last_check_timestamp'] = UpdateManager.get_current_timestamp()
                import os
                rules_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'config', 'rules.yaml')
                with open(rules_path, 'w', encoding='utf-8') as f:
                    yaml.dump(local_rules, f, allow_unicode=True, sort_keys=False)

        except requests.RequestException as e:
            console.print(f"âŒ [bold red]æ£€æŸ¥æ›´æ–°å¤±è´¥:[/bold red] {e}")
        except yaml.YAMLError as e:
            console.print(f"âŒ [bold red]è§£æè¿œç¨‹æˆ–æœ¬åœ°è§„åˆ™æ–‡ä»¶å¤±è´¥:[/bold red] {e}")
        except Exception as e:
            console.print(f"âŒ [bold red]æ›´æ–°è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯:[/bold red] {e}")

class ProxyManager:
    """ä»£ç†ç®¡ç†å·¥å…·ç±» (Proxy management utility class)"""
    
    @staticmethod
    def format_proxy(proxy_url):
        """
        æ ¼å¼åŒ–ä»£ç†URL (Format proxy URL)
        
        Args:
            proxy_url (str): ä»£ç†URL (Proxy URL)
            
        Returns:
            dict: æ ¼å¼åŒ–åçš„ä»£ç†é…ç½® (Formatted proxy configuration)
        """
        if proxy_url.startswith('socks5://'):
            return {
                "http": proxy_url,
                "https": proxy_url
            }
        else:
            return {
                "http": proxy_url if proxy_url.startswith('http') else f'http://{proxy_url}',
                "https": proxy_url if proxy_url.startswith('http') else f'http://{proxy_url}'
            } 