import os
import json
from datetime import datetime
from urllib.parse import urlparse
from .i18n import i18n

class FileOutputManager:
    """
    æ–‡ä»¶è¾“å‡ºç®¡ç†å™¨ç±»
    è´Ÿè´£å¤„ç†å„ç§æ–‡ä»¶æ ¼å¼çš„è¾“å‡º
    """

    def __init__(self, output_manager):
        """
        åˆå§‹åŒ–æ–‡ä»¶è¾“å‡ºç®¡ç†å™¨

        Args:
            output_manager (OutputManager): è¾“å‡ºç®¡ç†å™¨å®ä¾‹
        """
        self.output_manager = output_manager
        self.console = output_manager.console

    def save_results(self, target_url, config_args):
        """
        ä¿å­˜æ‰«æç»“æœåˆ°æ–‡ä»¶

        Args:
            target_url (str): ç›®æ ‡URL
            config_args: é…ç½®å‚æ•°å¯¹è±¡
        """
        if not self.output_manager.output_file:
            return

        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            output_dir = os.path.dirname(self.output_manager.output_file)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir)

            file_ext = os.path.splitext(self.output_manager.output_file)[1].lower()

            # æ•°æ®å»é‡å’Œæ’åº
            unique_results = self._deduplicate_results()
            sorted_results = self._sort_results(unique_results)

            # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©è¾“å‡ºæ ¼å¼
            if file_ext == '.json':
                self._save_as_json(sorted_results, target_url, config_args)
            elif file_ext == '.txt':
                self._save_as_txt(sorted_results, target_url)
            elif file_ext == '.csv':
                self._save_as_csv(sorted_results)
            elif file_ext == '.html':
                self._save_as_html(sorted_results, target_url)
            elif file_ext == '.xml':
                self._save_as_xml(sorted_results, target_url)
            elif file_ext == '.xlsx':
                self._save_as_excel(sorted_results, target_url)
            elif file_ext == '.md':
                self._save_as_markdown(sorted_results, target_url)
            else:
                # é»˜è®¤ä¿å­˜ä¸ºJSONæ ¼å¼
                self.output_manager.output_file = self.output_manager.output_file.rsplit('.', 1)[0] + '.json'
                self._save_as_json(sorted_results, target_url, config_args)
                self.output_manager.print_warning(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œå·²ä¿å­˜ä¸ºJSONæ ¼å¼")

            # è¾“å‡ºæ–‡ä»¶ä¿¡æ¯
            file_size = os.path.getsize(self.output_manager.output_file)
            file_size_str = self._format_file_size(file_size)

            if not self.output_manager.silent_mode:
                self.console.print(
                    f"\n[green bold]ğŸ’¾All Results saved to:[/green bold] [blue]{self.output_manager.output_file}[/blue]")
                self.console.print(
                    f"[dim]ğŸ“ File size: {file_size_str} | URLs: {len(sorted_results)} | Unique: {len(unique_results)} total[/dim]")

        except Exception as e:
            self.output_manager.print_error(f"Save failed: {str(e)}")

    def _deduplicate_results(self):
        """å»é‡ç»“æœ"""
        seen_urls = set()
        unique_results = []

        for result in self.output_manager.results:
            url = result['url']
            if url not in seen_urls:
                seen_urls.add(url)
                unique_results.append(result)

        return unique_results

    def _sort_results(self, results):
        """æ’åºç»“æœ - æŒ‰URLå­—æ¯é¡ºåº"""
        return sorted(results, key=lambda x: x['url'])

    def _format_file_size(self, size_bytes):
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        if size_bytes == 0:
            return "0 B"

        size_names = ["B", "KB", "MB", "GB"]
        i = 0
        while size_bytes >= 1024 and i < len(size_names) - 1:
            size_bytes /= 1024.0
            i += 1

        return f"{size_bytes:.1f} {size_names[i]}"

    def _save_as_json(self, results, target_url, config_args):
        """ä¿å­˜ä¸ºJSONæ ¼å¼"""
        scan_duration = datetime.now() - self.output_manager.stats["start_time"]

        output_data = {
            "metadata": {
                "version": "1,0",
                "tool": "Api-Finder",
                "scan_time": datetime.now().isoformat(),
                "target_url": target_url,
                "scan_duration_seconds": scan_duration.total_seconds(),
                "proxy_used": getattr(config_args, 'proxy', None) if config_args else "Direct",
                "total_results": len(results),
                "unique_results": len(self._deduplicate_results())
            },
            "statistics": {
                **self.output_manager.stats,
                "start_time": self.output_manager.stats["start_time"].isoformat(),
                "success_rate": round((self.output_manager.stats["successful_requests"] / max(1,
                                                                                              self.output_manager.stats[
                                                                                                  "successful_requests"] +
                                                                                              self.output_manager.stats[
                                                                                                  "failed_requests"])) * 100,
                                      2)
            },
            "results": results,
            "configuration": {
                "timeout": getattr(config_args, 'timeout', 10) if config_args else 10,
                "delay": getattr(config_args, 'delay', 0.5) if config_args else 0.5,
                "verbose": getattr(config_args, 'verbose', False) if config_args else False,
                "silent": getattr(config_args, 'silent', False) if config_args else False,
                "random_ua": getattr(config_args, 'random', False) if config_args else False
            }
        }

        with open(self.output_manager.output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)


    # TXT
    def _save_as_txt(self, results, target_url):
        """ä¿å­˜ä¸ºTXTæ ¼å¼"""
        with open(self.output_manager.output_file, 'w', encoding='utf-8') as f:
            # å†™å…¥æ–‡ä»¶å¤´
            f.write("=" * 60 + "\n")
            f.write(f"{i18n.get('output_header')}\n")
            f.write("=" * 60 + "\n")
            f.write(f"{i18n.get('output_target')}: {target_url}\n")
            f.write(f"{i18n.get('output_scan_time')}: {datetime.now().isoformat()}\n")
            f.write(f"æ‰«æç”¨æ—¶: {(datetime.now() - self.output_manager.stats['start_time']).total_seconds():.1f}ç§’\n")
            f.write(f"{i18n.get('output_endpoints_found')}: {len(results)}\n")
            f.write(f"æˆåŠŸè¯·æ±‚: {self.output_manager.stats['successful_requests']}\n")
            f.write(f"å¤±è´¥è¯·æ±‚: {self.output_manager.stats['failed_requests']}\n")
            f.write("-" * 60 + "\n\n")

            # æŒ‰æ¥æºåˆ†ç»„è¾“å‡º
            sources = {}
            for result in results:
                source = result['source'] if result['source'] else 'Unknown'
                if source not in sources:
                    sources[source] = []
                sources[source].append(result)

            for source, source_results in sources.items():
                f.write(f"ğŸ“ æ¥æº: {source}\n")
                f.write("-" * 30 + "\n")
                for result in source_results:
                    f.write(f"{result['url']}\n")
                f.write("\n")

    def _save_as_csv(self, results):
        """ä¿å­˜ä¸ºCSVæ ¼å¼"""
        import csv
        with open(self.output_manager.output_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            # å†™å…¥å¤´éƒ¨
            writer.writerow(['URL', 'Source', 'Timestamp', 'Source_Type', 'Domain'])

            for result in results:
                url = result['url']
                source = result['source'] if result['source'] else 'Unknown'
                timestamp = result['timestamp']

                # åˆ†æURLç±»å‹
                url_type = self._analyze_url_type(url)

                # æå–åŸŸå
                try:
                    domain = urlparse(url).netloc
                except:
                    domain = 'Unknown'

                writer.writerow([url, source, timestamp, url_type, domain])

    def _save_as_html(self, results, target_url):
        """ä¿å­˜ä¸ºHTMLæ ¼å¼"""
        html_content = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>API Finder - æ‰«æç»“æœ</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{ 
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; 
            margin: 20px; 
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            min-height: 100vh;
        }}
        .container {{ 
            max-width: 1200px; 
            margin: 0 auto; 
            background: white; 
            padding: 30px; 
            border-radius: 12px; 
            box-shadow: 0 8px 32px rgba(0,0,0,0.1);
        }}
        h1 {{ 
            color: #333; 
            text-align: center; 
            margin-bottom: 30px;
            font-size: 2.5em;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }}
        .stats {{ 
            display: grid; 
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); 
            gap: 20px; 
            margin: 30px 0; 
        }}
        .stat {{ 
            text-align: center; 
            padding: 20px; 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 10px;
            color: white;
            transition: transform 0.3s ease;
        }}
        .stat:hover {{ transform: translateY(-5px); }}
        .stat-value {{ 
            font-size: 2em; 
            font-weight: bold; 
            margin-bottom: 5px;
        }}
        .stat-label {{ 
            font-size: 0.9em; 
            opacity: 0.9;
        }}
        .info-section {{
            margin: 30px 0;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 8px;
            border-left: 4px solid #007bff;
        }}
        .info-section strong {{
            color: #007bff;
        }}
        table {{ 
            width: 100%; 
            border-collapse: collapse; 
            margin-top: 30px;
            background: white;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        }}
        th, td {{ 
            padding: 15px; 
            text-align: left; 
            border-bottom: 1px solid #eee; 
        }}
        th {{ 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }}
        tr:hover {{ 
            background-color: #f8f9ff; 
            transition: background-color 0.3s ease;
        }}
        .url-link {{ 
            color: #007bff; 
            text-decoration: none; 
            font-weight: 500;
            transition: all 0.3s ease;
            position: relative;
        }}
        .url-link:hover {{ 
            color: #0056b3;
            text-decoration: underline;
            transform: translateX(5px);
        }}
        .url-link::before {{
            content: 'ğŸ”—';
            margin-right: 5px;
            opacity: 0.7;
        }}
        .source {{ 
            color: #666; 
            font-size: 0.9em;
            background: #e9ecef;
            padding: 4px 8px;
            border-radius: 4px;
            display: inline-block;
        }}
        .timestamp {{ 
            color: #888; 
            font-size: 0.85em;
            font-family: monospace;
        }}
        .filter-section {{
            margin: 30px 0;
            display: flex;
            gap: 15px;
            align-items: center;
            flex-wrap: wrap;
        }}
        .filter-section input {{ 
            padding: 12px 16px; 
            border: 2px solid #ddd; 
            border-radius: 25px; 
            font-size: 14px;
            transition: border-color 0.3s ease;
            flex: 1;
            min-width: 300px;
        }}
        .filter-section input:focus {{
            outline: none;
            border-color: #007bff;
            box-shadow: 0 0 0 3px rgba(0,123,255,0.1);
        }}
        .btn {{
            padding: 10px 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            border-radius: 25px;
            cursor: pointer;
            font-size: 14px;
            transition: transform 0.3s ease;
        }}
        .btn:hover {{
            transform: translateY(-2px);
        }}
        .url-type {{
            font-size: 0.8em;
            padding: 3px 8px;
            border-radius: 12px;
            font-weight: 500;
            text-transform: uppercase;
        }}
        .url-type.api {{ background: #d4edda; color: #155724; }}
        .url-type.js {{ background: #fff3cd; color: #856404; }}
        .url-type.css {{ background: #d1ecf1; color: #0c5460; }}
        .url-type.image {{ background: #f8d7da; color: #721c24; }}
        .url-type.other {{ background: #e2e3e5; color: #383d41; }}
        .copy-btn {{
            background: transparent;
            border: 1px solid #007bff;
            color: #007bff;
            padding: 2px 8px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 12px;
            margin-left: 10px;
            transition: all 0.3s ease;
        }}
        .copy-btn:hover {{
            background: #007bff;
            color: white;
        }}
        .footer {{
            margin-top: 50px;
            text-align: center;
            color: #666;
            font-size: 0.9em;
        }}
        @media (max-width: 768px) {{
            .stats {{ grid-template-columns: 1fr 1fr; }}
            .filter-section {{ flex-direction: column; }}
            .filter-section input {{ min-width: 100%; }}
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ” API Finder æ‰«æç»“æœ</h1>

        <div class="stats">
            <div class="stat">
                <div class="stat-value">{len(results)}</div>
                <div class="stat-label">å‘ç°çš„URL</div>
            </div>
            <div class="stat">
                <div class="stat-value">{self.output_manager.stats['successful_requests']}</div>
                <div class="stat-label">æˆåŠŸè¯·æ±‚</div>
            </div>
            <div class="stat">
                <div class="stat-value">{self.output_manager.stats['failed_requests']}</div>
                <div class="stat-label">å¤±è´¥è¯·æ±‚</div>
            </div>
            <div class="stat">
                <div class="stat-value">{(datetime.now() - self.output_manager.stats['start_time']).total_seconds():.1f}s</div>
                <div class="stat-label">æ‰«æç”¨æ—¶</div>
            </div>
        </div>

        <div class="info-section">
            <p><strong>ğŸ¯ ç›®æ ‡URL:</strong> <a href="{target_url}" target="_blank" class="url-link">{target_url}</a></p>
            <p><strong>ğŸ• æ‰«ææ—¶é—´:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <p><strong>ğŸ“Š æ‰«æçŠ¶æ€:</strong> {"âœ… å®Œæˆ" if len(results) > 0 else "âš ï¸ æœªå‘ç°APIç«¯ç‚¹"}</p>
        </div>

        <div class="filter-section">
            <input type="text" id="filterInput" placeholder="ğŸ” è¿‡æ»¤URLï¼ˆæ”¯æŒæ­£åˆ™è¡¨è¾¾å¼ï¼‰..." onkeyup="filterResults()">
            <button class="btn" onclick="exportResults()">ğŸ“„ å¯¼å‡ºç»“æœ</button>
            <button class="btn" onclick="clearFilter()">ğŸ—‘ï¸ æ¸…é™¤è¿‡æ»¤</button>
        </div>

        <table id="resultsTable">
            <thead>
                <tr>
                    <th>ğŸ”— URL</th>
                    <th>ğŸ“ æ¥æº</th>
                    <th>ğŸ·ï¸ ç±»å‹</th>
                    <th>â° æ—¶é—´</th>
                    <th>ğŸ› ï¸ æ“ä½œ</th>
                </tr>
            </thead>
            <tbody>
"""

        for result in results:
            url = result['url']
            source = result['source'] if result['source'] else 'Unknown'
            timestamp = result['timestamp']
            url_type = self._analyze_url_type(url)

            # æ ¼å¼åŒ–æ—¶é—´
            try:
                time_obj = datetime.fromisoformat(timestamp)
                formatted_time = time_obj.strftime('%H:%M:%S')
            except:
                formatted_time = timestamp

            # ç”Ÿæˆç±»å‹æ ‡ç­¾çš„CSSç±»
            type_class = 'api' if 'api' in url.lower() else 'js' if '.js' in url else 'css' if '.css' in url else 'image' if any(
                ext in url.lower() for ext in ['.jpg', '.png', '.gif', '.svg']) else 'other'

            html_content += f"""
                <tr>
                    <td>
                        <a href="{url}" class="url-link" target="_blank" rel="noopener noreferrer">{url}</a>
                    </td>
                    <td><span class="source">{source.split('/')[-1] if source else 'Unknown'}</span></td>
                    <td><span class="url-type {type_class}">{url_type}</span></td>
                    <td><span class="timestamp">{formatted_time}</span></td>
                    <td>
                        <button class="copy-btn" onclick="copyToClipboard('{url}')">ğŸ“‹ å¤åˆ¶</button>
                    </td>
                </tr>
"""

        html_content += f"""
            </tbody>
        </table>

        <div class="footer">
            <p>Generated by <strong>API Finder</strong> â€¢ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <p>æ€»å…±æ‰¾åˆ° <strong>{len(results)}</strong> ä¸ªURL</p>
        </div>
    </div>

    <script>
        function filterResults() {{
            const input = document.getElementById('filterInput');
            const filter = input.value.toLowerCase();
            const table = document.getElementById('resultsTable');
            const rows = table.getElementsByTagName('tr');

            for (let i = 1; i < rows.length; i++) {{
                const url = rows[i].getElementsByTagName('td')[0].textContent.toLowerCase();
                const source = rows[i].getElementsByTagName('td')[1].textContent.toLowerCase();
                const type = rows[i].getElementsByTagName('td')[2].textContent.toLowerCase();

                if (url.indexOf(filter) > -1 || source.indexOf(filter) > -1 || type.indexOf(filter) > -1) {{
                    rows[i].style.display = '';
                }} else {{
                    rows[i].style.display = 'none';
                }}
            }}
        }}

        function clearFilter() {{
            document.getElementById('filterInput').value = '';
            filterResults();
        }}

        function copyToClipboard(url) {{
            navigator.clipboard.writeText(url).then(function() {{
                // åˆ›å»ºæç¤º
                const btn = event.target;
                const originalText = btn.textContent;
                btn.textContent = 'âœ… å·²å¤åˆ¶';
                btn.style.background = '#28a745';
                btn.style.color = 'white';

                setTimeout(() => {{
                    btn.textContent = originalText;
                    btn.style.background = 'transparent';
                    btn.style.color = '#007bff';
                }}, 1000);
            }});
        }}

        function exportResults() {{
            const table = document.getElementById('resultsTable');
            const rows = table.getElementsByTagName('tr');
            let csv = 'åºå·,URL,æ¥æº,ç±»å‹,æ—¶é—´\\n';

            for (let i = 1; i < rows.length; i++) {{
                if (rows[i].style.display !== 'none') {{
                    const cells = rows[i].getElementsByTagName('td');
                    const url = cells[0].textContent;
                    const source = cells[1].textContent;
                    const type = cells[2].textContent;
                    const time = cells[3].textContent;
                    csv += `${{i}},"${{url}}","${{source}}","${{type}}","${{time}}"\\n`;
                }}
            }}

            const blob = new Blob([csv], {{ type: 'text/csv;charset=utf-8;' }});
            const link = document.createElement('a');
            link.href = URL.createObjectURL(blob);
            link.download = 'api_finder_results.csv';
            link.click();
        }}

        // æ·»åŠ é”®ç›˜å¿«æ·é”®
        document.addEventListener('keydown', function(e) {{
            if (e.ctrlKey && e.key === 'f') {{
                e.preventDefault();
                document.getElementById('filterInput').focus();
            }}
        }});
    </script>
</body>
</html>
"""

        with open(self.output_manager.output_file, 'w', encoding='utf-8') as f:
            f.write(html_content)

    def _save_as_xml(self, results, target_url):
        """ä¿å­˜ä¸ºXMLæ ¼å¼"""
        xml_content = f"""<?xml version="1.0" encoding="UTF-8"?>
<api_scan_results>
    <metadata>
        <tool>Api-Finder</tool>
        <version>0.3.1</version>
        <scan_time>{datetime.now().isoformat()}</scan_time>
        <target_url>{target_url}</target_url>
        <total_results>{len(results)}</total_results>
    </metadata>
    <statistics>
        <successful_requests>{self.output_manager.stats['successful_requests']}</successful_requests>
        <failed_requests>{self.output_manager.stats['failed_requests']}</failed_requests>
        <api_endpoints>{self.output_manager.stats['api_endpoints']}</api_endpoints>
        <scan_duration>{(datetime.now() - self.output_manager.stats['start_time']).total_seconds():.1f}</scan_duration>
    </statistics>
    <results>
"""

        for result in results:
            url = result['url']
            source = result['source'] if result['source'] else 'Unknown'
            timestamp = result['timestamp']
            url_type = self._analyze_url_type(url)

            xml_content += f"""
        <result>
            <url><![CDATA[{url}]]></url>
            <source><![CDATA[{source}]]></source>
            <type>{url_type}</type>
            <timestamp>{timestamp}</timestamp>
        </result>
"""

        xml_content += """
    </results>
</api_scan_results>
"""

        with open(self.output_manager.output_file, 'w', encoding='utf-8') as f:
            f.write(xml_content)

    def _save_as_excel(self, results, target_url):
        """ä¿å­˜ä¸ºExcelæ ¼å¼"""
        try:
            import openpyxl
            from openpyxl.styles import Font, Alignment, PatternFill

            wb = openpyxl.Workbook()
            ws = wb.active
            ws.title = "APIæ‰«æç»“æœ"

            # è®¾ç½®æ ‡é¢˜æ ·å¼
            title_font = Font(bold=True, size=12)
            header_fill = PatternFill(start_color="E8F4F8", end_color="E8F4F8", fill_type="solid")

            # å†™å…¥å¤´éƒ¨ä¿¡æ¯
            ws['A1'] = 'API Finder æ‰«æç»“æœ'
            ws['A1'].font = Font(bold=True, size=16)
            ws['A2'] = f'ç›®æ ‡URL: {target_url}'
            ws['A3'] = f'æ‰«ææ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}'
            ws['A4'] = f'å‘ç°URLæ•°é‡: {len(results)}'

            # è®¾ç½®è¡¨æ ¼å¤´éƒ¨
            headers = ['URL', 'æ¥æº', 'ç±»å‹', 'åŸŸå', 'æ—¶é—´æˆ³']
            for i, header in enumerate(headers, 1):
                cell = ws.cell(row=6, column=i, value=header)
                cell.font = title_font
                cell.fill = header_fill

            # å†™å…¥æ•°æ®
            for row, result in enumerate(results, 7):
                ws.cell(row=row, column=1, value=result['url'])
                ws.cell(row=row, column=2, value=result['source'] if result['source'] else 'Unknown')
                ws.cell(row=row, column=3, value=self._analyze_url_type(result['url']))
                try:
                    domain = urlparse(result['url']).netloc
                except:
                    domain = 'Unknown'
                ws.cell(row=row, column=4, value=domain)
                ws.cell(row=row, column=5, value=result['timestamp'])

            # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 50)
                ws.column_dimensions[column_letter].width = adjusted_width

            wb.save(self.output_manager.output_file)

        except ImportError:
            self.output_manager.print_error("éœ€è¦å®‰è£…openpyxlåº“æ‰èƒ½ä¿å­˜Excelæ ¼å¼: pip install openpyxl")
            # å›é€€åˆ°CSVæ ¼å¼
            self.output_manager.output_file = self.output_manager.output_file.rsplit('.', 1)[0] + '.csv'
            self._save_as_csv(results)

    def _save_as_markdown(self, results, target_url):
        """ä¿å­˜ä¸ºMarkdownæ ¼å¼"""
        md_content = f"""# ğŸ” API Finder æ‰«æç»“æœ

## ğŸ“Š æ‰«æä¿¡æ¯

- **ç›®æ ‡URL**: {target_url}
- **æ‰«ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **å‘ç°URLæ•°é‡**: {len(results)}
- **æˆåŠŸè¯·æ±‚**: {self.output_manager.stats['successful_requests']}
- **å¤±è´¥è¯·æ±‚**: {self.output_manager.stats['failed_requests']}
- **æ‰«æç”¨æ—¶**: {(datetime.now() - self.output_manager.stats['start_time']).total_seconds():.1f}ç§’

## ğŸ¯ å‘ç°çš„APIç«¯ç‚¹

| URL | æ¥æº | ç±»å‹ | æ—¶é—´ |
|-----|------|------|------|
"""

        for result in results:
            url = result['url']
            source = result['source'] if result['source'] else 'Unknown'
            source_display = source.split('/')[-1] if source else 'Unknown'
            url_type = self._analyze_url_type(url)

            try:
                time_obj = datetime.fromisoformat(result['timestamp'])
                formatted_time = time_obj.strftime('%H:%M:%S')
            except:
                formatted_time = result['timestamp']

            md_content += f"| {url} | {source_display} | {url_type} | {formatted_time} |\n"

        md_content += f"""

## ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯

- æ€»URLæ•°é‡: {len(results)}
- å”¯ä¸€URLæ•°é‡: {len(self._deduplicate_results())}
- æˆåŠŸç‡: {round((self.output_manager.stats['successful_requests'] / max(1, self.output_manager.stats['successful_requests'] + self.output_manager.stats['failed_requests'])) * 100, 2)}%

---
*ç”Ÿæˆå·¥å…·: Api-Finder v0.3.1*
"""

        with open(self.output_manager.output_file, 'w', encoding='utf-8') as f:
            f.write(md_content)

    def _analyze_url_type(self, url):
        """åˆ†æURLç±»å‹"""
        url_lower = url.lower()

        if any(keyword in url_lower for keyword in ['api', 'rest', 'graphql']):
            return 'API'
        elif url_lower.endswith('.json'):
            return 'JSON'
        elif url_lower.endswith('.xml'):
            return 'XML'
        elif any(keyword in url_lower for keyword in ['ajax', 'xhr']):
            return 'AJAX'
        elif any(keyword in url_lower for keyword in ['.php', '.jsp', '.asp']):
            return 'Dynamic'
        elif any(keyword in url_lower for keyword in ['.js', '.css', '.html']):
            return 'Static'
        else:
            return 'Other'