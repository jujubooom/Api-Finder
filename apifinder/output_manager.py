#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¾“å‡ºç®¡ç†æ¨¡å— (Output Manager Module)
è´Ÿè´£å¤„ç†Api-Finderçš„æ‰€æœ‰è¾“å‡ºåŠŸèƒ½ï¼ŒåŒ…æ‹¬ç»ˆç«¯è¾“å‡ºå’Œæ–‡ä»¶è¾“å‡º
"""

import os
import json
import time
from datetime import datetime
from urllib.parse import urlparse
from rich.console import Console
from rich.text import Text
from rich.panel import Panel
from rich.table import Table
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn
from rich.rule import Rule
from .i18n import i18n


class OutputManager:
    """
    ä½¿ç”¨Richåº“çš„è¾“å‡ºç®¡ç†å™¨ç±»ï¼Œæä¾›ç¾è§‚çš„ç»ˆç«¯è¾“å‡ºå’Œå¤šç§æ–‡ä»¶è¾“å‡ºæ ¼å¼
    
    Attributes:
        silent_mode (bool): é™é»˜æ¨¡å¼ï¼Œåªè¾“å‡ºå‘ç°çš„APIç«¯ç‚¹
        verbose_mode (bool): è¯¦ç»†è¾“å‡ºæ¨¡å¼
        output_file (str): è¾“å‡ºæ–‡ä»¶è·¯å¾„
        results (list): ç»“æœåˆ—è¡¨
        stats (dict): ç»Ÿè®¡ä¿¡æ¯
        console (Console): Rich consoleå¯¹è±¡
        results_table (Table): ç»“æœè¡¨æ ¼
    """
    
    def __init__(self, silent_mode, verbose_mode=False, output_file=None):
        """
        åˆå§‹åŒ–è¾“å‡ºç®¡ç†å™¨
        
        Args:
            silent_mode (bool): é™é»˜æ¨¡å¼
            verbose_mode (bool): è¯¦ç»†è¾“å‡ºæ¨¡å¼
            output_file (str): è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        self.silent_mode = silent_mode
        self.verbose_mode = verbose_mode
        self.output_file = output_file
        self.console = Console()
        self.results = []
        self.stats = {
            "total_urls": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "api_endpoints": 0,
            "start_time": datetime.now()
        }
        self.results_table = Table(title="ğŸ” Discovered API Endpoints", border_style="green")
        self.results_table.add_column("ğŸ“ URL", style="cyan", no_wrap=False)
        self.results_table.add_column("ğŸ“„ Source", style="yellow", max_width=30)
        self.results_table.add_column("â° Time", style="dim", max_width=10)
    
    def print_info(self, text):
        """æ‰“å°ä¿¡æ¯"""
        if not self.silent_mode:
            self.console.print(text)
    
    def print_verbose(self, text):
        """æ‰“å°è¯¦ç»†ä¿¡æ¯"""
        if self.verbose_mode and not self.silent_mode:
            self.console.print(f"[dim][DEBUG][/dim] {text}")
    
    def print_url(self, url, source=""):
        """æ‰“å°å‘ç°çš„URL"""
        if self.silent_mode:
            # é™é»˜æ¨¡å¼ä½¿ç”¨Richçš„printè€Œä¸æ˜¯æ™®é€šprint
            self.console.print(url, highlight=False)
        else:
            # æ·»åŠ åˆ°ç»“æœè¡¨æ ¼
            source_display = source.split('/')[-1] if source else "unknown"
            time_display = datetime.now().strftime("%H:%M:%S")
            self.results_table.add_row(url, source_display, time_display)
            
            if source:
                self.console.print(f"[green bold]âœ“[/green bold] [blue]{url}[/blue] [dim](from: {source_display})[/dim]")
            else:
                self.console.print(f"[green bold]âœ“[/green bold] [blue]{url}[/blue]")
        
        # ä¿å­˜ç»“æœ
        self.results.append({
            "url": url,
            "source": source,
            "timestamp": datetime.now().isoformat()
        })
        self.stats["api_endpoints"] += 1
    
    def print_error(self, text):
        """æ‰“å°é”™è¯¯ä¿¡æ¯"""
        if not self.silent_mode:
            self.console.print(f"[red bold]âœ—[/red bold] {text}")
    
    def print_warning(self, text):
        """æ‰“å°è­¦å‘Šä¿¡æ¯"""
        if not self.silent_mode:
            self.console.print(f"[yellow bold]âš [/yellow bold] {text}")
    
    def print_success(self, text):
        """æ‰“å°æˆåŠŸä¿¡æ¯"""
        if not self.silent_mode:
            self.console.print(f"[green bold]âœ“[/green bold] {text}")

    def print_title(self, url, title):
        """æ‰“å°æˆåŠŸè¯·æ±‚çš„é¡µé¢æ ‡é¢˜"""
        if not self.silent_mode:
            text = Text()
            text.append("ğŸ“„ ", style="green")
            text.append(f"{title}", style="yellow")
            text.append(" â†’ ", style="dim")
            text.append(f"{url}", style="cyan dim")
            self.console.print(text)

    def print_proxy_mode(self, proxies):
        """è¾“å‡ºä½¿ç”¨çš„ä»£ç†æ¨¡å¼"""
        if not self.silent_mode:
            if proxies:
                proxy_table = Table(title="ğŸŒ Proxy Configuration", border_style="blue")
                proxy_table.add_column("Type", style="cyan")
                proxy_table.add_column("Address", style="green")
                
                if isinstance(proxies, list):
                    for proxy in proxies:
                        proxy_table.add_row("SOCKS5", proxy)
                elif isinstance(proxies, dict):
                    for protocol, proxy in proxies.items():
                        proxy_table.add_row(protocol.upper(), proxy)
                
                self.console.print(proxy_table)
            else:
                self.console.print("[yellow]ğŸ’» Direct connection (no proxy)[/yellow]")
            self.console.print(Rule(style="dim"))

    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        if not self.silent_mode:
            # è®¡ç®—æ‰«ææ—¶é—´
            scan_duration = datetime.now() - self.stats["start_time"]
            duration_str = f"{scan_duration.total_seconds():.1f}s"
            
            # åˆ›å»ºç»Ÿè®¡è¡¨æ ¼
            stats_table = Table(title="ğŸ“Š Scan Statistics", border_style="cyan")
            stats_table.add_column("Item", style="yellow bold")
            stats_table.add_column("Value", style="green bold", justify="right")
            
            stats_table.add_row("ğŸ¯ Total URLs", str(self.stats['total_urls']))
            stats_table.add_row("âœ… Successful Requests", str(self.stats['successful_requests']))
            stats_table.add_row("âŒ Failed Requests", str(self.stats['failed_requests']))
            stats_table.add_row("ğŸ” API Endpoints Found", str(self.stats['api_endpoints']))
            stats_table.add_row("â±ï¸ Scan Duration", duration_str)
            
            # è®¡ç®—æˆåŠŸç‡
            total_requests = self.stats['successful_requests'] + self.stats['failed_requests']
            if total_requests > 0:
                success_rate = (self.stats['successful_requests'] / total_requests) * 100
                stats_table.add_row("ğŸ“ˆ Success Rate", f"{success_rate:.1f}%")
            
            self.console.print(Rule(style="dim"))
            self.console.print(stats_table)
            
            # å¦‚æœæ‰¾åˆ°äº†APIç«¯ç‚¹ï¼Œæ˜¾ç¤ºç»“æœè¡¨æ ¼
            if self.stats['api_endpoints'] > 0 and not self.silent_mode:
                self.console.print(Rule(style="dim"))
                self.console.print(self.results_table)
    
    def create_progress(self, total_tasks=None):
        """åˆ›å»ºè¿›åº¦æ¡"""
        if self.silent_mode:
            return None
        
        return Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            TimeElapsedColumn(),
            console=self.console,
            expand=True
        )


class FileOutputManager:
    """
    æ–‡ä»¶è¾“å‡ºç®¡ç†å™¨ç±»
    è´Ÿè´£å¤„ç†å„ç§æ–‡ä»¶æ ¼å¼çš„è¾“å‡º
    """
    
    def __init__(self, output_manager):
        """
        åˆå§‹åŒ–æ–‡ä»¶è¾“å‡ºç®¡ç†å™¨
        
        Args:
            output_manager (OutputManager): è¾“å‡ºç®¡ç†å™¨å®ä¾‹
        """
        self.output_manager = output_manager
        self.console = output_manager.console
    
    def save_results(self, target_url, config_args):
        """
        ä¿å­˜æ‰«æç»“æœåˆ°æ–‡ä»¶
        
        Args:
            target_url (str): ç›®æ ‡URL
            config_args: é…ç½®å‚æ•°å¯¹è±¡
        """
        if not self.output_manager.output_file:
            return
        
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            output_dir = os.path.dirname(self.output_manager.output_file)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir)
            
            file_ext = os.path.splitext(self.output_manager.output_file)[1].lower()
            
            # æ•°æ®å»é‡å’Œæ’åº
            unique_results = self._deduplicate_results()
            sorted_results = self._sort_results(unique_results)
            
            # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©è¾“å‡ºæ ¼å¼
            if file_ext == '.json':
                self._save_as_json(sorted_results, target_url, config_args)
            elif file_ext == '.txt':
                self._save_as_txt(sorted_results, target_url)
            elif file_ext == '.csv':
                self._save_as_csv(sorted_results)
            elif file_ext == '.html':
                self._save_as_html(sorted_results, target_url)
            elif file_ext == '.xml':
                self._save_as_xml(sorted_results, target_url)
            elif file_ext == '.xlsx':
                self._save_as_excel(sorted_results, target_url)
            elif file_ext == '.md':
                self._save_as_markdown(sorted_results, target_url)
            else:
                # é»˜è®¤ä¿å­˜ä¸ºJSONæ ¼å¼
                self.output_manager.output_file = self.output_manager.output_file.rsplit('.', 1)[0] + '.json'
                self._save_as_json(sorted_results, target_url, config_args)
                self.output_manager.print_warning(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œå·²ä¿å­˜ä¸ºJSONæ ¼å¼")
            
            # è¾“å‡ºæ–‡ä»¶ä¿¡æ¯
            file_size = os.path.getsize(self.output_manager.output_file)
            file_size_str = self._format_file_size(file_size)
            
            if not self.output_manager.silent_mode:
                self.console.print(f"\n[green bold]ğŸ’¾ Results saved to:[/green bold] [blue]{self.output_manager.output_file}[/blue]")
                self.console.print(f"[dim]ğŸ“ File size: {file_size_str} | URLs: {len(sorted_results)} | Unique: {len(unique_results)} total[/dim]")
                
        except Exception as e:
            self.output_manager.print_error(f"Save failed: {str(e)}")
    
    def _deduplicate_results(self):
        """å»é‡ç»“æœ"""
        seen_urls = set()
        unique_results = []
        
        for result in self.output_manager.results:
            url = result['url']
            if url not in seen_urls:
                seen_urls.add(url)
                unique_results.append(result)
        
        return unique_results
    
    def _sort_results(self, results):
        """æ’åºç»“æœ - æŒ‰URLå­—æ¯é¡ºåº"""
        return sorted(results, key=lambda x: x['url'])
    
    def _format_file_size(self, size_bytes):
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        if size_bytes == 0:
            return "0 B"
        
        size_names = ["B", "KB", "MB", "GB"]
        i = 0
        while size_bytes >= 1024 and i < len(size_names) - 1:
            size_bytes /= 1024.0
            i += 1
        
        return f"{size_bytes:.1f} {size_names[i]}"
    
    def _save_as_json(self, results, target_url, config_args):
        """ä¿å­˜ä¸ºJSONæ ¼å¼"""
        scan_duration = datetime.now() - self.output_manager.stats["start_time"]
        
        output_data = {
            "metadata": {
                "version": "0.3.1",
                "tool": "Api-Finder",
                "scan_time": datetime.now().isoformat(),
                "target_url": target_url,
                "scan_duration_seconds": scan_duration.total_seconds(),
                "proxy_used": getattr(config_args, 'proxy', None) if config_args else "Direct",
                "total_results": len(results),
                "unique_results": len(self._deduplicate_results())
            },
            "statistics": {
                **self.output_manager.stats,
                "start_time": self.output_manager.stats["start_time"].isoformat(),
                "success_rate": round((self.output_manager.stats["successful_requests"] / max(1, self.output_manager.stats["successful_requests"] + self.output_manager.stats["failed_requests"])) * 100, 2)
            },
            "results": results,
            "configuration": {
                "timeout": getattr(config_args, 'timeout', 10) if config_args else 10,
                "delay": getattr(config_args, 'delay', 0.5) if config_args else 0.5,
                "verbose": getattr(config_args, 'verbose', False) if config_args else False,
                "silent": getattr(config_args, 'silent', False) if config_args else False,
                "random_ua": getattr(config_args, 'random', False) if config_args else False
            }
        }
        
        with open(self.output_manager.output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    def _save_as_txt(self, results, target_url):
        """ä¿å­˜ä¸ºTXTæ ¼å¼"""
        with open(self.output_manager.output_file, 'w', encoding='utf-8') as f:
            # å†™å…¥æ–‡ä»¶å¤´
            f.write("=" * 60 + "\n")
            f.write(f"{i18n.get('output_header')}\n")
            f.write("=" * 60 + "\n")
            f.write(f"{i18n.get('output_target')}: {target_url}\n")
            f.write(f"{i18n.get('output_scan_time')}: {datetime.now().isoformat()}\n")
            f.write(f"æ‰«æç”¨æ—¶: {(datetime.now() - self.output_manager.stats['start_time']).total_seconds():.1f}ç§’\n")
            f.write(f"{i18n.get('output_endpoints_found')}: {len(results)}\n")
            f.write(f"æˆåŠŸè¯·æ±‚: {self.output_manager.stats['successful_requests']}\n")
            f.write(f"å¤±è´¥è¯·æ±‚: {self.output_manager.stats['failed_requests']}\n")
            f.write("-" * 60 + "\n\n")
            
            # æŒ‰æ¥æºåˆ†ç»„è¾“å‡º
            sources = {}
            for result in results:
                source = result['source'] if result['source'] else 'Unknown'
                if source not in sources:
                    sources[source] = []
                sources[source].append(result)
            
            for source, source_results in sources.items():
                f.write(f"ğŸ“ æ¥æº: {source}\n")
                f.write("-" * 30 + "\n")
                for result in source_results:
                    f.write(f"{result['url']}\n")
                f.write("\n")
    
    def _save_as_csv(self, results):
        """ä¿å­˜ä¸ºCSVæ ¼å¼"""
        import csv
        with open(self.output_manager.output_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            # å†™å…¥å¤´éƒ¨
            writer.writerow(['URL', 'Source', 'Timestamp', 'Source_Type', 'Domain'])
            
            for result in results:
                url = result['url']
                source = result['source'] if result['source'] else 'Unknown'
                timestamp = result['timestamp']
                
                # åˆ†æURLç±»å‹
                url_type = self._analyze_url_type(url)
                
                # æå–åŸŸå
                try:
                    domain = urlparse(url).netloc
                except:
                    domain = 'Unknown'
                
                writer.writerow([url, source, timestamp, url_type, domain])
    
    def _save_as_html(self, results, target_url):
        """ä¿å­˜ä¸ºHTMLæ ¼å¼"""
        html_content = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>API Finder - æ‰«æç»“æœ</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
        h1 {{ color: #333; text-align: center; }}
        .stats {{ display: flex; justify-content: space-around; margin: 20px 0; }}
        .stat {{ text-align: center; padding: 10px; background: #e8f4f8; border-radius: 4px; }}
        .stat-value {{ font-size: 24px; font-weight: bold; color: #2196F3; }}
        .stat-label {{ font-size: 14px; color: #666; }}
        table {{ width: 100%; border-collapse: collapse; margin-top: 20px; }}
        th, td {{ padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }}
        th {{ background-color: #f8f9fa; font-weight: bold; }}
        .url-link {{ color: #2196F3; text-decoration: none; }}
        .url-link:hover {{ text-decoration: underline; }}
        .source {{ color: #666; font-size: 12px; }}
        .timestamp {{ color: #888; font-size: 11px; }}
        .filter-box {{ margin: 20px 0; }}
        .filter-box input {{ padding: 8px; border: 1px solid #ddd; border-radius: 4px; width: 300px; }}
    </style>
    <script>
        function filterResults() {{
            const input = document.getElementById('filterInput');
            const filter = input.value.toLowerCase();
            const table = document.getElementById('resultsTable');
            const rows = table.getElementsByTagName('tr');
            
            for (let i = 1; i < rows.length; i++) {{
                const url = rows[i].getElementsByTagName('td')[0].textContent.toLowerCase();
                if (url.indexOf(filter) > -1) {{
                    rows[i].style.display = '';
                }} else {{
                    rows[i].style.display = 'none';
                }}
            }}
        }}
    </script>
</head>
<body>
    <div class="container">
        <h1>ğŸ” API Finder æ‰«æç»“æœ</h1>
        
        <div class="stats">
            <div class="stat">
                <div class="stat-value">{len(results)}</div>
                <div class="stat-label">å‘ç°çš„URL</div>
            </div>
            <div class="stat">
                <div class="stat-value">{self.output_manager.stats['successful_requests']}</div>
                <div class="stat-label">æˆåŠŸè¯·æ±‚</div>
            </div>
            <div class="stat">
                <div class="stat-value">{self.output_manager.stats['failed_requests']}</div>
                <div class="stat-label">å¤±è´¥è¯·æ±‚</div>
            </div>
            <div class="stat">
                <div class="stat-value">{(datetime.now() - self.output_manager.stats['start_time']).total_seconds():.1f}s</div>
                <div class="stat-label">æ‰«æç”¨æ—¶</div>
            </div>
        </div>
        
        <p><strong>ç›®æ ‡URL:</strong> {target_url}</p>
        <p><strong>æ‰«ææ—¶é—´:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        
        <div class="filter-box">
            <input type="text" id="filterInput" placeholder="è¿‡æ»¤URL..." onkeyup="filterResults()">
        </div>
        
        <table id="resultsTable">
            <thead>
                <tr>
                    <th>URL</th>
                    <th>æ¥æº</th>
                    <th>ç±»å‹</th>
                    <th>æ—¶é—´</th>
                </tr>
            </thead>
            <tbody>
"""
        
        for result in results:
            url = result['url']
            source = result['source'] if result['source'] else 'Unknown'
            timestamp = result['timestamp']
            url_type = self._analyze_url_type(url)
            
            # æ ¼å¼åŒ–æ—¶é—´
            try:
                time_obj = datetime.fromisoformat(timestamp)
                formatted_time = time_obj.strftime('%H:%M:%S')
            except:
                formatted_time = timestamp
            
            html_content += f"""
                <tr>
                    <td><a href="{url}" class="url-link" target="_blank">{url}</a></td>
                    <td><span class="source">{source.split('/')[-1] if source else 'Unknown'}</span></td>
                    <td>{url_type}</td>
                    <td><span class="timestamp">{formatted_time}</span></td>
                </tr>
"""
        
        html_content += """
            </tbody>
        </table>
    </div>
</body>
</html>
"""
        
        with open(self.output_manager.output_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
    
    def _save_as_xml(self, results, target_url):
        """ä¿å­˜ä¸ºXMLæ ¼å¼"""
        xml_content = f"""<?xml version="1.0" encoding="UTF-8"?>
<api_scan_results>
    <metadata>
        <tool>Api-Finder</tool>
        <version>0.3.1</version>
        <scan_time>{datetime.now().isoformat()}</scan_time>
        <target_url>{target_url}</target_url>
        <total_results>{len(results)}</total_results>
    </metadata>
    <statistics>
        <successful_requests>{self.output_manager.stats['successful_requests']}</successful_requests>
        <failed_requests>{self.output_manager.stats['failed_requests']}</failed_requests>
        <api_endpoints>{self.output_manager.stats['api_endpoints']}</api_endpoints>
        <scan_duration>{(datetime.now() - self.output_manager.stats['start_time']).total_seconds():.1f}</scan_duration>
    </statistics>
    <results>
"""
        
        for result in results:
            url = result['url']
            source = result['source'] if result['source'] else 'Unknown'
            timestamp = result['timestamp']
            url_type = self._analyze_url_type(url)
            
            xml_content += f"""
        <result>
            <url><![CDATA[{url}]]></url>
            <source><![CDATA[{source}]]></source>
            <type>{url_type}</type>
            <timestamp>{timestamp}</timestamp>
        </result>
"""
        
        xml_content += """
    </results>
</api_scan_results>
"""
        
        with open(self.output_manager.output_file, 'w', encoding='utf-8') as f:
            f.write(xml_content)
    
    def _save_as_excel(self, results, target_url):
        """ä¿å­˜ä¸ºExcelæ ¼å¼"""
        try:
            import openpyxl
            from openpyxl.styles import Font, Alignment, PatternFill
            
            wb = openpyxl.Workbook()
            ws = wb.active
            ws.title = "APIæ‰«æç»“æœ"
            
            # è®¾ç½®æ ‡é¢˜æ ·å¼
            title_font = Font(bold=True, size=12)
            header_fill = PatternFill(start_color="E8F4F8", end_color="E8F4F8", fill_type="solid")
            
            # å†™å…¥å¤´éƒ¨ä¿¡æ¯
            ws['A1'] = 'API Finder æ‰«æç»“æœ'
            ws['A1'].font = Font(bold=True, size=16)
            ws['A2'] = f'ç›®æ ‡URL: {target_url}'
            ws['A3'] = f'æ‰«ææ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}'
            ws['A4'] = f'å‘ç°URLæ•°é‡: {len(results)}'
            
            # è®¾ç½®è¡¨æ ¼å¤´éƒ¨
            headers = ['URL', 'æ¥æº', 'ç±»å‹', 'åŸŸå', 'æ—¶é—´æˆ³']
            for i, header in enumerate(headers, 1):
                cell = ws.cell(row=6, column=i, value=header)
                cell.font = title_font
                cell.fill = header_fill
            
            # å†™å…¥æ•°æ®
            for row, result in enumerate(results, 7):
                ws.cell(row=row, column=1, value=result['url'])
                ws.cell(row=row, column=2, value=result['source'] if result['source'] else 'Unknown')
                ws.cell(row=row, column=3, value=self._analyze_url_type(result['url']))
                try:
                    domain = urlparse(result['url']).netloc
                except:
                    domain = 'Unknown'
                ws.cell(row=row, column=4, value=domain)
                ws.cell(row=row, column=5, value=result['timestamp'])
            
            # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 50)
                ws.column_dimensions[column_letter].width = adjusted_width
            
            wb.save(self.output_manager.output_file)
            
        except ImportError:
            self.output_manager.print_error("éœ€è¦å®‰è£…openpyxlåº“æ‰èƒ½ä¿å­˜Excelæ ¼å¼: pip install openpyxl")
            # å›é€€åˆ°CSVæ ¼å¼
            self.output_manager.output_file = self.output_manager.output_file.rsplit('.', 1)[0] + '.csv'
            self._save_as_csv(results)
    
    def _save_as_markdown(self, results, target_url):
        """ä¿å­˜ä¸ºMarkdownæ ¼å¼"""
        md_content = f"""# ğŸ” API Finder æ‰«æç»“æœ

## ğŸ“Š æ‰«æä¿¡æ¯

- **ç›®æ ‡URL**: {target_url}
- **æ‰«ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **å‘ç°URLæ•°é‡**: {len(results)}
- **æˆåŠŸè¯·æ±‚**: {self.output_manager.stats['successful_requests']}
- **å¤±è´¥è¯·æ±‚**: {self.output_manager.stats['failed_requests']}
- **æ‰«æç”¨æ—¶**: {(datetime.now() - self.output_manager.stats['start_time']).total_seconds():.1f}ç§’

## ğŸ¯ å‘ç°çš„APIç«¯ç‚¹

| URL | æ¥æº | ç±»å‹ | æ—¶é—´ |
|-----|------|------|------|
"""
        
        for result in results:
            url = result['url']
            source = result['source'] if result['source'] else 'Unknown'
            source_display = source.split('/')[-1] if source else 'Unknown'
            url_type = self._analyze_url_type(url)
            
            try:
                time_obj = datetime.fromisoformat(result['timestamp'])
                formatted_time = time_obj.strftime('%H:%M:%S')
            except:
                formatted_time = result['timestamp']
            
            md_content += f"| {url} | {source_display} | {url_type} | {formatted_time} |\n"
        
        md_content += f"""

## ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯

- æ€»URLæ•°é‡: {len(results)}
- å”¯ä¸€URLæ•°é‡: {len(self._deduplicate_results())}
- æˆåŠŸç‡: {round((self.output_manager.stats['successful_requests'] / max(1, self.output_manager.stats['successful_requests'] + self.output_manager.stats['failed_requests'])) * 100, 2)}%

---
*ç”Ÿæˆå·¥å…·: Api-Finder v0.3.1*
"""
        
        with open(self.output_manager.output_file, 'w', encoding='utf-8') as f:
            f.write(md_content)
    
    def _analyze_url_type(self, url):
        """åˆ†æURLç±»å‹"""
        url_lower = url.lower()
        
        if any(keyword in url_lower for keyword in ['api', 'rest', 'graphql']):
            return 'API'
        elif url_lower.endswith('.json'):
            return 'JSON'
        elif url_lower.endswith('.xml'):
            return 'XML'
        elif any(keyword in url_lower for keyword in ['ajax', 'xhr']):
            return 'AJAX'
        elif any(keyword in url_lower for keyword in ['.php', '.jsp', '.asp']):
            return 'Dynamic'
        elif any(keyword in url_lower for keyword in ['.js', '.css', '.html']):
            return 'Static'
        else:
            return 'Other' 